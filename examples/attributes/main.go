package main

import (
	"fmt"
	"github.com/eternalsad/formula"
	"math"
	"unicode"
)

func main() {
	parser := formula.NewSimpleParser()

	// Test cases
	testCases := []string{
		"A/DC-1",
		"asdsadsadsdasd",
		//"A + B",
		//"A + B * C",
		//"(A + B) * C",
		//"Ð•Ð¡Ð›Ð˜(age = 18 Ð˜ 1 = 1) Ð¢ÐžÐ“Ð”Ð salary * 1.2 Ð˜ÐÐÐ§Ð• salary",
		//"Ð•Ð¡Ð›Ð˜ 1 -(B/A)/B=0 Ð˜Ð›Ð˜ 1 -(B/A)/B >1 Ð¢ÐžÐ“Ð”Ð 1 Ð˜ÐÐÐ§Ð• (1-(B-A)/B*(-1))",
	}

	fmt.Println("=== Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð°Ñ€ÑÐµÑ€Ð° Ñ„Ð¾Ñ€Ð¼ÑƒÐ» ===\n")

	for i, testCase := range testCases {
		fmt.Printf("Ð¢ÐµÑÑ‚ %d: %s\n", i+1, testCase)

		ast, err := parser.ParseString(toUpperLatinOnlyUnicode(testCase))
		if err != nil {
			fmt.Printf("âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: %v\n", err)
		} else {
			//fmt.Printf("âœ… AST: %s\n", ast.String())

			// Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ñ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð½Ñ‹Ð¼Ð¸ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸ÑÐ¼Ð¸
			// Ð¿Ð¾Ð´ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð½ÑƒÐ¶Ð½Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð² Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ðµ
			// Ð´Ð¾Ð±Ð°Ð²Ð¸Ð¼ Ð¿Ð¾Ð»Ðµ attributes
			// {
			//.  "A": {
			//.   "letter":"A",
			//.   "id": "12"
			//.   }
			// }
			// Ð·Ð°Ñ‚ÐµÐ¼ Ð¿Ð¾ÑÑ‚ÐµÐ¿ÐµÐ½Ð½Ð¾ Ð¸Ð· json Ð´Ð¾ÑÑ‚Ð°Ñ‚ÑŒ Ð² Ñ€ÐµÐ¿Ð¾Ð¸Ð·Ñ‚Ð¾Ñ€Ð¸Ð¸ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð½ÑƒÐ¶Ð½Ñ‹Ðµ Ð¿Ð¾ Ð°Ð¹Ð´Ð¸
			// Ð¸ Ð²Ð¾Ñ‚ ÑÑŽÐ´Ð° Ð²ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ Ð² Ð²Ð¸Ð´Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ…
			variables := map[string]float64{
				"A":      69456935.000000,
				"B":      69456939.000000,
				"C":      2,
				"age":    18,
				"salary": 50000,
			}

			result, evalErr := ast.Evaluate(&formula.Context{
				Variables: variables,
				Functions: nil,
			})

			result = roundFloat(result, 2)
			if evalErr != nil {
				fmt.Printf("âš ï¸  ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ñ: %v\n", evalErr)
			} else {
				fmt.Printf("ðŸ“Š Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚: %.2f\n", result)
			}
		}
		fmt.Println()
	}

	// Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð¿Ð¾ÑˆÐ°Ð³Ð¾Ð²Ð¾Ð³Ð¾ Ñ€Ð°Ð·Ð±Ð¾Ñ€Ð°
	fmt.Println("=== ÐŸÐ¾ÑˆÐ°Ð³Ð¾Ð²Ñ‹Ð¹ Ñ€Ð°Ð·Ð±Ð¾Ñ€ Ñ„Ð¾Ñ€Ð¼ÑƒÐ»Ñ‹ 'IF(age > 18, salary * 1.2, salary)' ===")
	demonstrateTokenization("IF(age > 18, salary * 1.2, salary)")
}

// demonstrateTokenization shows how the lexer tokenizes input
func demonstrateTokenization(input string) {
	lexer := formula.NewLexer(input)
	fmt.Printf("Ð˜ÑÑ…Ð¾Ð´Ð½Ð°Ñ ÑÑ‚Ñ€Ð¾ÐºÐ°: %s\n", input)
	fmt.Println("Ð¢Ð¾ÐºÐµÐ½Ñ‹:")

	for {
		token := lexer.NextToken()
		if token.Type == formula.TokenEOF {
			break
		}

		var tokenTypeName string
		switch token.Type {
		case formula.TokenNumber:
			tokenTypeName = "NUMBER"
		case formula.TokenVariable:
			tokenTypeName = "VARIABLE"
		case formula.TokenOperator:
			tokenTypeName = "OPERATOR"
		case formula.TokenParenOpen:
			tokenTypeName = "PAREN_OPEN"
		case formula.TokenParenClose:
			tokenTypeName = "PAREN_CLOSE"
		case formula.TokenComma:
			tokenTypeName = "COMMA"
		case formula.TokenFunction:
			tokenTypeName = "FUNCTION"
		}

		fmt.Printf("  %s: '%s' (Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ñ %d)\n", tokenTypeName, token.Value, token.Pos)
	}
}

func roundFloat(val float64, precision uint) float64 {
	ratio := math.Pow(10, float64(precision))
	return math.Round(val*ratio) / ratio
}
func toUpperLatinOnlyUnicode(s string) string {
	runes := []rune(s)
	result := make([]rune, len(runes))

	for i, r := range runes {
		// ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð»Ð¸ ÑÐ¸Ð¼Ð²Ð¾Ð» Ð»Ð°Ñ‚Ð¸Ð½ÑÐºÐ¾Ð¹ Ð±ÑƒÐºÐ²Ð¾Ð¹ Ð½Ð¸Ð¶Ð½ÐµÐ³Ð¾ Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°
		if r >= 'a' && r <= 'z' && unicode.In(r, unicode.Latin) {
			result[i] = unicode.ToUpper(r)
		} else {
			result[i] = r // ÐžÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ð±ÐµÐ· Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹
		}
	}

	return string(result)
}
